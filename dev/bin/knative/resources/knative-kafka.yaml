---
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-broker-config
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
data:
  default.topic.partitions: "1"
  default.topic.replication.factor: "1"
  bootstrap.servers: "my-cluster-kafka-bootstrap.kafka:9092"
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: kafkasinks.eventing.knative.dev
  labels:
    duck.knative.dev/addressable: "true"
    knative.dev/crd-install: "true"
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  group: eventing.knative.dev
  names:
    kind: KafkaSink
    plural: kafkasinks
    singular: kafkasink
    categories:
      - all
      - knative
      - eventing
  scope: Namespaced
  versions:
    - name: v1alpha1
      served: true
      storage: true
      subresources:
        status: { }
      schema:
        openAPIV3Schema:
          description: 'Kafka Sink is Addressable, it receives events and send them to a Kafka topic.'
          type: object
          properties:
            spec:
              description: 'Spec defines the desired state of the Kafka Sink.'
              type: object
              required:
                - topic
                - bootstrapServers
              properties:
                topic:
                  description: 'Topic name to send events.'
                  type: string
                numPartitions:
                  description: 'Number of topic partitions.
                                If not specified the topic isn''t automatically created, and the system supposes that
                                the topic is already present.'
                  type: integer
                  format: int32
                replicationFactor:
                  description: 'Topic replication factor.
                                If not specified the topic isn''t automatically created, and the system supposes that
                                the topic is already present.'
                  type: integer
                  format: int32
                bootstrapServers:
                  description: 'A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.'
                  type: array
                  minLength: 1
                  items:
                    type: string
                contentMode:
                  description: |
                    CloudEvent content mode of Kafka messages sent to the topic.
                    Possible values: [structured, binary] (default: structured)
                    - https://github.com/cloudevents/spec/blob/v1.0/spec.md#message
                      - https://github.com/cloudevents/spec/blob/v1.0/kafka-protocol-binding.md#33-structured-content-mode
                      - https://github.com/cloudevents/spec/blob/v1.0/kafka-protocol-binding.md#32-binary-content-mode
                  type: string
                  enum:
                    - structured
                    - binary
                  default: structured
                auth:
                  description: 'Auth configurations'
                  type: object
                  properties:
                    secret:
                      description: 'Auth secret'
                      type: object
                      properties:
                        ref:
                          description: |
                            Secret reference.
                          type: object
                          required:
                            - name
                          properties:
                            name:
                              description: 'Secret name'
                              type: string
            status:
              description: 'Status represents the current state of the KafkaSink. This data may be out of date.'
              type: object
              properties:
                address:
                  description: 'Kafka Sink is Addressable. It exposes the endpoint as an
                      URI to get events delivered to a Kafka topic.'
                  type: object
                  properties:
                    url:
                      type: string
                annotations:
                  description: 'Annotations is additional Status fields for the Resource
                      to save some additional State as well as convey more information
                      to the user. This is roughly akin to Annotations on any k8s resource,
                      just the reconciler conveying richer information outwards.'
                  type: object
                  x-kubernetes-preserve-unknown-fields: true
                conditions:
                  description: 'Conditions the latest available observations of a resource''s
                      current state.'
                  type: array
                  items:
                    type: object
                    required:
                      - type
                      - status
                    properties:
                      lastTransitionTime:
                        description: 'LastTransitionTime is the last time the condition
                            transitioned from one status to another. We use VolatileTime
                            in place of metav1.Time to exclude this from creating
                            equality.Semantic differences (all other things held
                            constant).'
                        type: string
                      message:
                        description: 'A human readable message indicating details
                            about the transition.'
                        type: string
                      reason:
                        description: 'The reason for the condition''s last transition.'
                        type: string
                      severity:
                        description: 'Severity with which to treat failures of
                            this type of condition. When this is not specified,
                            it defaults to Error.'
                        type: string
                      status:
                        description: 'Status of the condition, one of True, False,
                            Unknown.'
                        type: string
                      type:
                        description: 'Type of condition.'
                        type: string
                observedGeneration:
                  description: 'ObservedGeneration is the ''Generation'' of the Service
                      that was last processed by the controller.'
                  type: integer
                  format: int64
      additionalPrinterColumns:
        - name: URL
          type: string
          jsonPath: .status.address.url
        - name: Age
          type: date
          jsonPath: .metadata.creationTimestamp
        - name: Ready
          type: string
          jsonPath: ".status.conditions[?(@.type==\"Ready\")].status"
        - name: Reason
          type: string
          jsonPath: ".status.conditions[?(@.type==\"Ready\")].reason"
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  labels:
    kafka.eventing.knative.dev/release: "v20211214-f1bb19a50"
    eventing.knative.dev/source: "true"
    duck.knative.dev/source: "true"
    knative.dev/crd-install: "true"
  annotations:
    registry.knative.dev/eventTypes: |
      [
        { "type": "dev.knative.kafka.event" }
      ]
  name: kafkasources.sources.knative.dev
spec:
  group: sources.knative.dev
  versions:
    - name: v1beta1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          x-kubernetes-preserve-unknown-fields: true
      subresources:
        status: {}
        scale:
          specReplicasPath: .spec.consumers
          statusReplicasPath: .status.consumers
          labelSelectorPath: .status.selector
      additionalPrinterColumns:
        - name: Topics
          type: string
          jsonPath: ".spec.topics"
        - name: BootstrapServers
          type: string
          jsonPath: ".spec.bootstrapServers"
        - name: Ready
          type: string
          jsonPath: ".status.conditions[?(@.type==\"Ready\")].status"
        - name: Reason
          type: string
          jsonPath: ".status.conditions[?(@.type==\"Ready\")].reason"
        - name: Age
          type: date
          jsonPath: .metadata.creationTimestamp
  names:
    categories:
      - all
      - knative
      - eventing
      - sources
    kind: KafkaSource
    plural: kafkasources
  scope: Namespaced
  conversion:
    strategy: Webhook
    webhook:
      conversionReviewVersions: ["v1", "v1beta1"]
      clientConfig:
        service:
          name: kafka-source-webhook
          namespace: knative-eventing
---
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: eventing-kafka-source-observer
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
    duck.knative.dev/source: "true"
rules:
  - apiGroups:
      - "sources.knative.dev"
    resources:
      - "kafkasources"
    verbs:
      - get
      - list
      - watch
---
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
  name: config-kafka-leader-election
  namespace: knative-eventing
  annotations:
    knative.dev/example-checksum: "96896b00"
data:
  _example: |
    leaseDuration: "15s"
    renewDeadline: "10s"
    retryPeriod: "2s"
    buckets: "1"
  leaseDuration: "15s"
  renewDeadline: "10s"
  retryPeriod: "2s"
---
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config-logging
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
data:
  config.xml: |
    <configuration>
      <appender name="jsonConsoleAppender" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>
      </appender>
      <root level="INFO">
        <appender-ref ref="jsonConsoleAppender"/>
      </root>
    </configuration>
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: knative-kafka-addressable-resolver
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
    duck.knative.dev/addressable: "true"
rules:
  - apiGroups:
      - eventing.knative.dev
    resources:
      - kafkasinks
      - kafkasinks/status
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - messaging.knative.dev
    resources:
      - kafkachannels
      - kafkachannels/status
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: knative-kafka-channelable-manipulator
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
    duck.knative.dev/channelable: "true"
rules:
  - apiGroups:
      - messaging.knative.dev
    resources:
      - kafkachannels
      - kafkachannels/status
    verbs:
      - create
      - get
      - list
      - watch
      - update
      - patch
      - delete
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kafka-controller
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
rules:
  - apiGroups:
      - "*"
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
      - update
      - create
  - apiGroups:
      - "*"
    resources:
      - pods
    verbs:
      - list
      - update
      - get
      - watch
  - apiGroups:
      - "*"
    resources:
      - events
    verbs:
      - patch
      - create
  - apiGroups:
      - "coordination.k8s.io"
    resources:
      - "leases"
    verbs:
      - get
      - list
      - create
      - update
      - delete
      - patch
      - watch
  - apiGroups:
      - "*"
    resources:
      - secrets
    verbs:
      - list
      - get
      - watch
  - apiGroups:
      - "*"
    resources:
      - nodes
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "apps"
    resources:
      - statefulsets
      - statefulsets/scale
    verbs:
      - get
      - list
      - watch
      - update
      - patch
  - apiGroups:
      - "internal.kafka.eventing.knative.dev"
    resources:
      - "consumers"
      - "consumers/status"
      - "consumergroups"
      - "consumergroups/status"
    verbs:
      - create
      - get
      - list
      - watch
      - patch
      - update
  - apiGroups:
      - "internal.kafka.eventing.knative.dev"
    resources:
      - "consumers/finalizers"
      - "consumergroups/finalizers"
    verbs:
      - update
  - apiGroups:
      - "eventing.knative.dev"
    resources:
      - "brokers"
      - "brokers/status"
      - "triggers"
      - "triggers/status"
      - "kafkasinks"
      - "kafkasinks/status"
    verbs:
      - list
      - get
      - watch
      - patch
      - update
  - apiGroups:
      - "eventing.knative.dev"
    resources:
      - "brokers/finalizers"
      - "triggers/finalizers"
      - "kafkasinks/finalizers"
    verbs:
      - update
  - apiGroups:
      - messaging.knative.dev
    resources:
      - kafkachannels
      - kafkachannels/status
    verbs:
      - get
      - list
      - watch
      - update
      - patch
  - apiGroups:
      - messaging.knative.dev
    resources:
      - subscriptions
      - subscriptions/status
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - messaging.knative.dev
    resources:
      - kafkachannels/finalizers
    verbs:
      - update
  - apiGroups:
      - sources.knative.dev
    resources:
      - kafkasources
      - kafkasources/status
    verbs:
      - get
      - list
      - watch
      - update
      - patch
  - apiGroups:
      - sources.knative.dev
    resources:
      - kafkasources/finalizers
    verbs:
      - update
---
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kafka-controller
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kafka-controller
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
subjects:
  - kind: ServiceAccount
    name: kafka-controller
    namespace: knative-eventing
roleRef:
  kind: ClusterRole
  name: kafka-controller
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kafka-controller-addressable-resolver
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
subjects:
  - kind: ServiceAccount
    name: kafka-controller
    namespace: knative-eventing
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: addressable-resolver
---
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-controller
  namespace: knative-eventing
  labels:
    app: kafka-controller
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    matchLabels:
      app: kafka-controller
  template:
    metadata:
      name: kafka-controller
      labels:
        app: kafka-controller
        kafka.eventing.knative.dev/release: v1.1.3
    spec:
      securityContext:
        runAsNonRoot: false
      serviceAccountName: kafka-controller
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: kafka-controller
                topologyKey: kubernetes.io/hostname
              weight: 100
      containers:
        - name: controller
          image: registry.ci.openshift.org/openshift/knative-v1.1.3:knative-eventing-kafka-broker-kafka-controller
          imagePullPolicy: IfNotPresent
          env:
            - name: BROKER_DATA_PLANE_CONFIG_MAP_NAMESPACE
              value: knative-eventing
            - name: CHANNEL_DATA_PLANE_CONFIG_MAP_NAMESPACE
              value: knative-eventing
            - name: SINK_DATA_PLANE_CONFIG_MAP_NAMESPACE
              value: knative-eventing
            - name: SOURCE_DATA_PLANE_CONFIG_MAP_NAMESPACE
              value: knative-eventing
            - name: BROKER_DATA_PLANE_CONFIG_MAP_NAME
              value: kafka-broker-brokers-triggers
            - name: CHANNEL_DATA_PLANE_CONFIG_MAP_NAME
              value: kafka-channel-channels-subscriptions
            - name: SINK_DATA_PLANE_CONFIG_MAP_NAME
              value: kafka-sink-sinks
            - name: SOURCE_DATA_PLANE_CONFIG_MAP_NAME
              value: kafka-source-sources
            - name: BROKER_DATA_PLANE_CONFIG_FORMAT
              value: json
            - name: CHANNEL_DATA_PLANE_CONFIG_FORMAT
              value: json
            - name: SINK_DATA_PLANE_CONFIG_FORMAT
              value: json
            - name: SOURCE_DATA_PLANE_CONFIG_FORMAT
              value: json
            - name: BROKER_INGRESS_NAME
              value: kafka-broker-ingress
            - name: CHANNEL_INGRESS_NAME
              value: kafka-channel-ingress
            - name: SINK_INGRESS_NAME
              value: kafka-sink-ingress
            - name: SOURCE_INGRESS_NAME
              value: kafka-source-ingress
            - name: BROKER_GENERAL_CONFIG_MAP_NAME
              value: kafka-broker-config
            - name: CHANNEL_GENERAL_CONFIG_MAP_NAME
              value: kafka-channel-config
            - name: SINK_GENERAL_CONFIG_MAP_NAME
              value: kafka-broker-config
            - name: SOURCE_GENERAL_CONFIG_MAP_NAME
              value: kafka-broker-config
            - name: BROKER_INGRESS_POD_PORT
              value: "8080"
            - name: CHANNEL_INGRESS_POD_PORT
              value: "8080"
            - name: SINK_INGRESS_POD_PORT
              value: "8080"
            - name: BROKER_SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CHANNEL_SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: SINK_SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: SOURCE_SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: BROKER_DEFAULT_BACKOFF_DELAY_MS
              value: "1000" # 1 second
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LEADERELECTION_NAME
              value: config-kafka-leader-election
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            - name: METRICS_DOMAIN
              value: knative.dev/eventing
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          ports:
            - containerPort: 9090
              name: metrics
          terminationMessagePolicy: FallbackToLogsOnError
          terminationMessagePath: /dev/temination-log
          securityContext:
            allowPrivilegeEscalation: false
            privileged: false
            readOnlyRootFilesystem: true
      restartPolicy: Always
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kafka-webhook-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
rules:
  - apiGroups:
      - ""
    resources:
      - "configmaps"
    verbs:
      - "get"
      - "list"
      - "watch"
  - apiGroups:
      - ""
    resources:
      - "secrets"
      - "namespaces"
    verbs:
      - "get"
      - "create"
      - "update"
      - "list"
      - "watch"
      - "patch"
  - apiGroups:
      - "apps"
    resources:
      - "deployments"
    verbs:
      - "get"
  - apiGroups:
      - "apps"
    resources:
      - "deployments/finalizers"
    verbs:
      - update
  - apiGroups:
      - "admissionregistration.k8s.io"
    resources:
      - "mutatingwebhookconfigurations"
      - "validatingwebhookconfigurations"
    verbs: &everything
      - "get"
      - "list"
      - "create"
      - "update"
      - "delete"
      - "patch"
      - "watch"
  - apiGroups:
      - "coordination.k8s.io"
    resources:
      - "leases"
    verbs: *everything
  - apiGroups:
      - ""
    resources:
      - "namespaces/finalizers"
    verbs:
      - "update"
  - apiGroups:
      - "eventing.knative.dev"
    resources:
      - "brokers"
    verbs:
      - list
      - get
      - watch
  - apiGroups:
      - messaging.knative.dev
    resources:
      - kafkachannels
    verbs:
      - get
      - list
---
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kafka-webhook-eventing
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kafka-webhook-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
subjects:
  - kind: ServiceAccount
    name: kafka-webhook-eventing
    namespace: knative-eventing
roleRef:
  kind: ClusterRole
  name: kafka-webhook-eventing
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: defaulting.webhook.kafka.eventing.knative.dev
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
webhooks:
  - admissionReviewVersions: [ "v1", "v1beta1" ]
    clientConfig:
      service:
        name: kafka-webhook-eventing
        namespace: knative-eventing
    sideEffects: None
    failurePolicy: Fail
    name: defaulting.webhook.kafka.eventing.knative.dev
    timeoutSeconds: 2
---
apiVersion: v1
kind: Secret
metadata:
  name: kafka-webhook-eventing-certs
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: validation.webhook.kafka.eventing.knative.dev
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
webhooks:
  - admissionReviewVersions: ["v1", "v1beta1"]
    clientConfig:
      service:
        name: kafka-webhook-eventing
        namespace: knative-eventing
    sideEffects: None
    failurePolicy: Fail
    name: validation.webhook.kafka.eventing.knative.dev
    timeoutSeconds: 2
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-webhook-eventing
  namespace: knative-eventing
  labels:
    app: kafka-webhook-eventing
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    matchLabels:
      app: kafka-webhook-eventing
  template:
    metadata:
      labels:
        app: kafka-webhook-eventing
        kafka.eventing.knative.dev/release: v1.1.3
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: kafka-webhook-eventing
                topologyKey: kubernetes.io/hostname
              weight: 100
      serviceAccountName: kafka-webhook-eventing
      securityContext:
        runAsNonRoot: false
      containers:
        - name: kafka-webhook-eventing
          terminationMessagePolicy: FallbackToLogsOnError
          image: registry.ci.openshift.org/openshift/knative-v1.1.3:knative-eventing-kafka-broker-webhook-kafka
          resources:
            requests:
              cpu: 20m
              memory: 20Mi
            limits:
              cpu: 200m
              memory: 200Mi
          env:
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LEADERELECTION_NAME
              value: config-kafka-leader-election
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: METRICS_DOMAIN
              value: knative.dev/eventing
            - name: WEBHOOK_NAME
              value: kafka-webhook-eventing
            - name: WEBHOOK_PORT
              value: "8443"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          securityContext:
            allowPrivilegeEscalation: false
          ports:
            - name: https-webhook
              containerPort: 8443
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
          readinessProbe: &probe
            periodSeconds: 1
            httpGet:
              scheme: HTTPS
              port: 8443
              httpHeaders:
                - name: k-kubelet-probe
                  value: "webhook"
          livenessProbe:
            <<: *probe
            initialDelaySeconds: 20
      terminationGracePeriodSeconds: 300
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-webhook-eventing
  namespace: knative-eventing
  labels:
    app: kafka-webhook-eventing
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  ports:
    - name: https-webhook
      port: 443
      targetPort: 8443
    - name: http-metrics
      port: 9090
      targetPort: 9090
  selector:
    app: kafka-webhook-eventing
---
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-kafka-broker-data-plane
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
data:
  config-kafka-broker-producer.properties: |
    key.serializer=org.apache.kafka.common.serialization.StringSerializer
    value.serializer=io.cloudevents.kafka.CloudEventSerializer
    acks=all
    buffer.memory=33554432
    retries=2147483647
    batch.size=16384
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=600000
    delivery.timeout.ms=120000
    linger.ms=0
    max.block.ms=60000
    max.request.size=1048576
    partitioner.class=org.apache.kafka.clients.producer.internals.DefaultPartitioner
    receive.buffer.bytes=-1
    request.timeout.ms=30000
    enable.idempotence=false
    max.in.flight.requests.per.connection=5
    metadata.max.age.ms=300000
    metrics.num.samples=2
    metrics.recording.level=INFO
    metrics.sample.window.ms=30000
    reconnect.backoff.max.ms=1000
    reconnect.backoff.ms=50
    retry.backoff.ms=100
  config-kafka-broker-consumer.properties: |
    key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
    value.deserializer=io.cloudevents.kafka.CloudEventDeserializer
    fetch.min.bytes=1
    heartbeat.interval.ms=3000
    max.partition.fetch.bytes=1048576
    session.timeout.ms=10000
    allow.auto.create.topics=true
    auto.offset.reset=earliest
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=540000
    default.api.timeout.ms=60000
    enable.auto.commit=false
    exclude.internal.topics=true
    fetch.max.bytes=52428800
    isolation.level=read_uncommitted
    max.poll.interval.ms=300000
    max.poll.records=500
    receive.buffer.bytes=65536
    request.timeout.ms=30000
    security.protocol=PLAINTEXT
    send.buffer.bytes=131072
    auto.commit.interval.ms=5000
    check.crcs=true
    fetch.max.wait.ms=500
    metadata.max.age.ms=600000
    reconnect.backoff.max.ms=1000
    retry.backoff.ms=100
  config-kafka-broker-webclient.properties: |
    idleTimeout=10000
  config-kafka-broker-httpserver.properties: |
    idleTimeout=0
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: knative-kafka-broker-data-plane
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
rules:
  - apiGroups:
      - "*"
    resources:
      - secrets
    verbs:
      - get
      - list
      - watch
---
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: knative-kafka-broker-data-plane
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: knative-kafka-broker-data-plane
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
subjects:
  - kind: ServiceAccount
    name: knative-kafka-broker-data-plane
    namespace: knative-eventing
roleRef:
  kind: ClusterRole
  name: knative-kafka-broker-data-plane
  apiGroup: rbac.authorization.k8s.io
---
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-broker-dispatcher
  namespace: knative-eventing
  labels:
    app: kafka-broker-dispatcher
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    matchLabels:
      app: kafka-broker-dispatcher
  template:
    metadata:
      name: kafka-broker-dispatcher
      labels:
        app: kafka-broker-dispatcher
        kafka.eventing.knative.dev/release: v1.1.3
    spec:
      serviceAccountName: knative-kafka-broker-data-plane
      securityContext:
        runAsNonRoot: false
      containers:
        - name: kafka-broker-dispatcher
          image: registry.ci.openshift.org/openshift/knative-v1.1.3:knative-eventing-kafka-broker-dispatcher
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - mountPath: /etc/config
              name: config-kafka-broker-data-plane
              readOnly: true
            - mountPath: /etc/brokers-triggers
              name: kafka-broker-brokers-triggers
              readOnly: true
            - mountPath: /tmp
              name: cache
            - mountPath: /etc/logging
              name: kafka-broker-config-logging
              readOnly: true
            - mountPath: /etc/tracing
              name: config-tracing
              readOnly: true
          ports:
            - containerPort: 9090
              name: http-metrics
              protocol: TCP
          env:
            - name: SERVICE_NAME
              value: "kafka-broker-dispatcher"
            - name: SERVICE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: PRODUCER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-broker-producer.properties
            - name: CONSUMER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-broker-consumer.properties
            - name: WEBCLIENT_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-broker-webclient.properties
            - name: DATA_PLANE_CONFIG_FILE_PATH
              value: /etc/brokers-triggers/data
            - name: EGRESSES_INITIAL_CAPACITY
              value: "20"
            - name: INSTANCE_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.uid
            - name: METRICS_PATH
              value: /metrics
            - name: METRICS_PORT
              value: "9090"
            - name: METRICS_PUBLISH_QUANTILES
              value: "false"
            - name: METRICS_JVM_ENABLED
              value: "false"
            - name: CONFIG_TRACING_PATH
              value: "/etc/tracing"
            - name: HTTP2_DISABLE
              value: "true"
            - name: WAIT_STARTUP_SECONDS
              value: "8"
          command:
            - "java"
          args:
            - "-Dlogback.configurationFile=/etc/logging/config.xml"
            - "-jar"
            - "/app/app.jar"
          livenessProbe:
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePolicy: FallbackToLogsOnError
          terminationMessagePath: /dev/temination-log
          securityContext:
            allowPrivilegeEscalation: false
            privileged: false
            readOnlyRootFilesystem: true
      volumes:
        - name: config-kafka-broker-data-plane
          configMap:
            name: config-kafka-broker-data-plane
        - name: kafka-broker-brokers-triggers
          configMap:
            name: kafka-broker-brokers-triggers
        - name: cache
          emptyDir: { }
        - name: kafka-broker-config-logging
          configMap:
            name: kafka-config-logging
        - name: config-tracing
          configMap:
            name: config-tracing
      restartPolicy: Always
      dnsConfig:
        options:
          - name: single-request-reopen
---
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-broker-receiver
  namespace: knative-eventing
  labels:
    app: kafka-broker-receiver
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    matchLabels:
      app: kafka-broker-receiver
  template:
    metadata:
      name: kafka-broker-receiver
      labels:
        app: kafka-broker-receiver
        kafka.eventing.knative.dev/release: v1.1.3
    spec:
      serviceAccountName: knative-kafka-broker-data-plane
      securityContext:
        runAsNonRoot: false
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: kafka-broker-receiver
                topologyKey: kubernetes.io/hostname
              weight: 100
      containers:
        - name: kafka-broker-receiver
          image: registry.ci.openshift.org/openshift/knative-v1.1.3:knative-eventing-kafka-broker-receiver
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - mountPath: /etc/config
              name: config-kafka-broker-data-plane
              readOnly: true
            - mountPath: /etc/brokers-triggers
              name: kafka-broker-brokers-triggers
              readOnly: true
            - mountPath: /tmp
              name: cache
            - mountPath: /etc/logging
              name: kafka-broker-config-logging
              readOnly: true
            - mountPath: /etc/tracing
              name: config-tracing
              readOnly: true
          ports:
            - containerPort: 9090
              name: http-metrics
              protocol: TCP
            - containerPort: 8080
              name: http
              protocol: TCP
          env:
            - name: SERVICE_NAME
              value: "kafka-broker-receiver"
            - name: SERVICE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: INGRESS_PORT
              value: "8080"
            - name: PRODUCER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-broker-producer.properties
            - name: HTTPSERVER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-broker-httpserver.properties
            - name: DATA_PLANE_CONFIG_FILE_PATH
              value: /etc/brokers-triggers/data
            - name: LIVENESS_PROBE_PATH
              value: /healthz
            - name: READINESS_PROBE_PATH
              value: /readyz
            - name: METRICS_PATH
              value: /metrics
            - name: METRICS_PORT
              value: "9090"
            - name: METRICS_PUBLISH_QUANTILES
              value: "false"
            - name: METRICS_JVM_ENABLED
              value: "false"
            - name: CONFIG_TRACING_PATH
              value: "/etc/tracing"
            - name: HTTP2_DISABLE
              value: "true"
            - name: WAIT_STARTUP_SECONDS
              value: "8"
          command:
            - "java"
          args:
            - "-Dlogback.configurationFile=/etc/logging/config.xml"
            - "-jar"
            - "/app/app.jar"
          livenessProbe:
            failureThreshold: 3
            httpGet:
              port: 8080
              path: /healthz
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              port: 8080
              path: /readyz
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePolicy: FallbackToLogsOnError
          terminationMessagePath: /dev/temination-log
          securityContext:
            allowPrivilegeEscalation: false
            privileged: false
            readOnlyRootFilesystem: true
      volumes:
        - name: kafka-broker-brokers-triggers
          configMap:
            name: kafka-broker-brokers-triggers
        - name: config-kafka-broker-data-plane
          configMap:
            name: config-kafka-broker-data-plane
        - name: cache
          emptyDir: { }
        - name: kafka-broker-config-logging
          configMap:
            name: kafka-config-logging
        - name: config-tracing
          configMap:
            name: config-tracing
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-broker-ingress
  namespace: knative-eventing
  labels:
    app: kafka-broker-receiver
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    app: kafka-broker-receiver
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8080
    - name: http-metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
---
---
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-kafka-sink-data-plane
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
data:
  config-kafka-sink-producer.properties: |
    key.serializer=org.apache.kafka.common.serialization.StringSerializer
    value.serializer=io.cloudevents.kafka.CloudEventSerializer
    acks=all
    buffer.memory=33554432
    retries=2147483647
    batch.size=16384
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=600000
    delivery.timeout.ms=120000
    linger.ms=0
    max.block.ms=60000
    max.request.size=1048576
    partitioner.class=org.apache.kafka.clients.producer.internals.DefaultPartitioner
    receive.buffer.bytes=-1
    request.timeout.ms=30000
    enable.idempotence=false
    max.in.flight.requests.per.connection=5
    metadata.max.age.ms=300000
    metrics.num.samples=2
    metrics.recording.level=INFO
    metrics.sample.window.ms=30000
    reconnect.backoff.max.ms=1000
    reconnect.backoff.ms=50
    retry.backoff.ms=100
  config-kafka-sink-httpserver.properties: |
    idleTimeout=0
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: knative-kafka-sink-data-plane
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
rules:
  - apiGroups:
      - "*"
    resources:
      - secrets
    verbs:
      - get
      - list
      - watch
---
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: knative-kafka-sink-data-plane
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: knative-kafka-sink-data-plane
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
subjects:
  - kind: ServiceAccount
    name: knative-kafka-sink-data-plane
    namespace: knative-eventing
roleRef:
  kind: ClusterRole
  name: knative-kafka-sink-data-plane
  apiGroup: rbac.authorization.k8s.io
---
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-sink-receiver
  namespace: knative-eventing
  labels:
    app: kafka-sink-receiver
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    matchLabels:
      app: kafka-sink-receiver
  template:
    metadata:
      name: kafka-sink-receiver
      labels:
        app: kafka-sink-receiver
        kafka.eventing.knative.dev/release: v1.1.3
    spec:
      serviceAccountName: knative-kafka-sink-data-plane
      securityContext:
        runAsNonRoot: false
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: kafka-sink-receiver
                topologyKey: kubernetes.io/hostname
              weight: 100
      containers:
        - name: kafka-sink-receiver
          image: registry.ci.openshift.org/openshift/knative-v1.1.3:knative-eventing-kafka-broker-receiver
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - mountPath: /etc/config
              name: config-kafka-sink-data-plane
              readOnly: true
            - mountPath: /etc/sinks
              name: kafka-sink-sinks
              readOnly: true
            - mountPath: /tmp
              name: cache
            - mountPath: /etc/logging
              name: kafka-sink-config-logging
              readOnly: true
            - mountPath: /etc/tracing
              name: config-tracing
              readOnly: true
          ports:
            - containerPort: 9090
              name: http-metrics
              protocol: TCP
            - containerPort: 8080
              name: http
              protocol: TCP
          env:
            - name: SERVICE_NAME
              value: "kafka-sink-receiver"
            - name: SERVICE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: INGRESS_PORT
              value: "8080"
            - name: PRODUCER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-sink-producer.properties
            - name: HTTPSERVER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-sink-httpserver.properties
            - name: DATA_PLANE_CONFIG_FILE_PATH
              value: /etc/sinks/data
            - name: LIVENESS_PROBE_PATH
              value: /healthz
            - name: READINESS_PROBE_PATH
              value: /readyz
            - name: METRICS_PATH
              value: /metrics
            - name: METRICS_PORT
              value: "9090"
            - name: METRICS_PUBLISH_QUANTILES
              value: "false"
            - name: METRICS_JVM_ENABLED
              value: "false"
            - name: CONFIG_TRACING_PATH
              value: "/etc/tracing"
            - name: HTTP2_DISABLE
              value: "true"
            - name: WAIT_STARTUP_SECONDS
              value: "8"
          command:
            - "java"
          args:
            - "-Dlogback.configurationFile=/etc/logging/config.xml"
            - "-jar"
            - "/app/app.jar"
          livenessProbe:
            failureThreshold: 3
            httpGet:
              port: 8080
              path: /healthz
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              port: 8080
              path: /readyz
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePolicy: FallbackToLogsOnError
          terminationMessagePath: /dev/temination-log
          securityContext:
            allowPrivilegeEscalation: false
            privileged: false
            readOnlyRootFilesystem: true
      volumes:
        - name: kafka-sink-sinks
          configMap:
            name: kafka-sink-sinks
        - name: config-kafka-sink-data-plane
          configMap:
            name: config-kafka-sink-data-plane
        - name: cache
          emptyDir: { }
        - name: kafka-sink-config-logging
          configMap:
            name: kafka-config-logging
        - name: config-tracing
          configMap:
            name: config-tracing
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-sink-ingress
  namespace: knative-eventing
  labels:
    app: kafka-sink-receiver
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    app: kafka-sink-receiver
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8080
    - name: http-metrics
      port: 9090
      protocol: TCP
      targetPort: 9090
---
---
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-kafka-source-data-plane
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
data:
  config-kafka-source-producer.properties: |
    key.serializer=org.apache.kafka.common.serialization.StringSerializer
    value.serializer=io.cloudevents.kafka.CloudEventSerializer
    acks=all
    buffer.memory=33554432
    retries=2147483647
    batch.size=16384
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=600000
    delivery.timeout.ms=120000
    linger.ms=0
    max.block.ms=60000
    max.request.size=1048576
    partitioner.class=org.apache.kafka.clients.producer.internals.DefaultPartitioner
    receive.buffer.bytes=-1
    request.timeout.ms=30000
    enable.idempotence=false
    max.in.flight.requests.per.connection=5
    metadata.max.age.ms=300000
    metrics.num.samples=2
    metrics.recording.level=INFO
    metrics.sample.window.ms=30000
    reconnect.backoff.max.ms=1000
    reconnect.backoff.ms=50
    retry.backoff.ms=100
  config-kafka-source-consumer.properties: |
    cloudevent.invalid.transformer.enabled=true
    cloudevent.invalid.kind.plural=kafkasources
    key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
    value.deserializer=io.cloudevents.kafka.CloudEventDeserializer
    fetch.min.bytes=1
    heartbeat.interval.ms=3000
    max.partition.fetch.bytes=1048576
    session.timeout.ms=10000
    allow.auto.create.topics=true
    auto.offset.reset=earliest
    client.dns.lookup=use_all_dns_ips
    connections.max.idle.ms=540000
    default.api.timeout.ms=60000
    enable.auto.commit=false
    exclude.internal.topics=true
    fetch.max.bytes=52428800
    isolation.level=read_uncommitted
    max.poll.interval.ms=300000
    max.poll.records=500
    receive.buffer.bytes=65536
    request.timeout.ms=30000
    security.protocol=PLAINTEXT
    send.buffer.bytes=131072
    auto.commit.interval.ms=5000
    check.crcs=true
    fetch.max.wait.ms=500
    metadata.max.age.ms=600000
    reconnect.backoff.max.ms=1000
    retry.backoff.ms=100
  config-kafka-source-webclient.properties: |
    idleTimeout=10000
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: knative-kafka-source-data-plane
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
rules:
  - apiGroups:
      - "*"
    resources:
      - secrets
    verbs:
      - get
      - list
      - watch
---
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: knative-kafka-source-data-plane
  namespace: knative-eventing
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
---
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: knative-kafka-source-data-plane
  labels:
    kafka.eventing.knative.dev/release: v1.1.3
subjects:
  - kind: ServiceAccount
    name: knative-kafka-source-data-plane
    namespace: knative-eventing
roleRef:
  kind: ClusterRole
  name: knative-kafka-source-data-plane
  apiGroup: rbac.authorization.k8s.io
---
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-source-dispatcher
  namespace: knative-eventing
  labels:
    app: kafka-source-dispatcher
    kafka.eventing.knative.dev/release: v1.1.3
spec:
  selector:
    matchLabels:
      app: kafka-source-dispatcher
  template:
    metadata:
      name: kafka-source-dispatcher
      labels:
        app: kafka-source-dispatcher
        kafka.eventing.knative.dev/release: v1.1.3
    spec:
      serviceAccountName: knative-kafka-source-data-plane
      securityContext:
        runAsNonRoot: false
      containers:
        - name: kafka-source-dispatcher
          image: registry.ci.openshift.org/openshift/knative-v1.1.3:knative-eventing-kafka-broker-dispatcher
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - mountPath: /etc/config
              name: config-kafka-source-data-plane
              readOnly: true
            - mountPath: /etc/sources
              name: kafka-source-sources
              readOnly: true
            - mountPath: /tmp
              name: cache
            - mountPath: /etc/logging
              name: kafka-config-logging
              readOnly: true
            - mountPath: /etc/tracing
              name: config-tracing
              readOnly: true
          ports:
            - containerPort: 9090
              name: http-metrics
              protocol: TCP
          env:
            - name: SERVICE_NAME
              value: "kafka-source-dispatcher"
            - name: SERVICE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: PRODUCER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-source-producer.properties
            - name: CONSUMER_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-source-consumer.properties
            - name: WEBCLIENT_CONFIG_FILE_PATH
              value: /etc/config/config-kafka-source-webclient.properties
            - name: DATA_PLANE_CONFIG_FILE_PATH
              value: /etc/sources/data
            - name: EGRESSES_INITIAL_CAPACITY
              value: "20"
            - name: INSTANCE_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.uid
            - name: METRICS_PATH
              value: /metrics
            - name: METRICS_PORT
              value: "9090"
            - name: METRICS_PUBLISH_QUANTILES
              value: "false"
            - name: METRICS_JVM_ENABLED
              value: "false"
            - name: CONFIG_TRACING_PATH
              value: "/etc/tracing"
            - name: HTTP2_DISABLE
              value: "true"
            - name: WAIT_STARTUP_SECONDS
              value: "8"
          command:
            - "java"
          args:
            - "-Dlogback.configurationFile=/etc/logging/config.xml"
            - "-jar"
            - "/app/app.jar"
          livenessProbe:
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 3
            successThreshold: 1
            timeoutSeconds: 1
          terminationMessagePolicy: FallbackToLogsOnError
          terminationMessagePath: /dev/temination-log
          securityContext:
            allowPrivilegeEscalation: false
            privileged: false
            readOnlyRootFilesystem: true
      volumes:
        - name: config-kafka-source-data-plane
          configMap:
            name: config-kafka-source-data-plane
        - name: kafka-source-sources
          configMap:
            name: kafka-source-sources
        - name: cache
          emptyDir: { }
        - name: kafka-config-logging
          configMap:
            name: kafka-config-logging
        - name: config-tracing
          configMap:
            name: config-tracing
      restartPolicy: Always
      dnsConfig:
        options:
          - name: single-request-reopen
